#321Brown Video
#Gradient descent
#Q.What is gradient Descent?
"""A. A way to converge towards some local minium of a cost function, such as the valley in the graph"""


#Gradient Descent:
"""

1.Cost surface

2.Stochastic gradient descent

3.Mini batches

4.Backpropagation : is algorithm for determining how a single training would like to nudge the anaylsis not just in terms of whether they should go up or down but in terms of what relative proprtions to those changes cause the most rapid decrease to the cost.
Q.But changing it into value is slow.
A.Solution: so you cahnge it into many mini batches and compute each step with respect to a mini-batch
"""

"""
Gradient"""